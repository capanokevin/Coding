{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The 3 most basic tasks of sentiment analysis are:\n- Polarity detection: \n- [Aspect Extraction](https://github.com/soujanyaporia/aspect-extraction):\nidentifying opinion targets in opinionated text. Can be done by POS detection\n- [Subjectivity detection](https://github.com/fractalego/subjectivity_classifier):\nIdentify objective and subjective sentences. Can be solved as a classification problem","metadata":{}},{"cell_type":"markdown","source":"#### NLP tasks with [spacy](https://spacy.io/)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"data/amazon_cellphones_multiclass.csv\")\ndf","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             asin                                         reviewText  overall\n0      B007D6J64K  Probably my favorite cover! Super sassy and ve...        5\n1      B007D6J64K          This case protects the phone from damage.        5\n2      B007D6J64K                                               Nice        4\n3      B007D6J64K  this was another of my favorite ones, thanks f...        5\n4      B007D6J64K           Decent case but not a lot of protection.        5\n...           ...                                                ...      ...\n29995  B0096QI0QK  it is so easy to put on your phone and it prot...        5\n29996  B0096QI0QK  Much better quality than I expected for the pr...        5\n29997  B0096QI0QK  This is one of the best screen protectors I ha...        4\n29998  B0096QI0QK  This kit included a microfiber cloth and soft ...        5\n29999  B0096QI0QK  This was the easiest screen protector to put o...        5\n\n[30000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asin</th>\n      <th>reviewText</th>\n      <th>overall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B007D6J64K</td>\n      <td>Probably my favorite cover! Super sassy and ve...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B007D6J64K</td>\n      <td>This case protects the phone from damage.</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B007D6J64K</td>\n      <td>Nice</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B007D6J64K</td>\n      <td>this was another of my favorite ones, thanks f...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B007D6J64K</td>\n      <td>Decent case but not a lot of protection.</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>B0096QI0QK</td>\n      <td>it is so easy to put on your phone and it prot...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>B0096QI0QK</td>\n      <td>Much better quality than I expected for the pr...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>B0096QI0QK</td>\n      <td>This is one of the best screen protectors I ha...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>B0096QI0QK</td>\n      <td>This kit included a microfiber cloth and soft ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>B0096QI0QK</td>\n      <td>This was the easiest screen protector to put o...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install spacy","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting spacy\n  Downloading spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n\u001b[K     |████████████████████████████████| 12.8 MB 4.1 MB/s eta 0:00:01\n\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n  Downloading catalogue-2.0.1-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (49.6.0.post20210108)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (2.25.1)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (20.9)\nCollecting pathy>=0.3.5\n  Downloading pathy-0.4.0-py3-none-any.whl (36 kB)\nCollecting blis<0.8.0,>=0.4.0\n  Downloading blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\n\u001b[K     |████████████████████████████████| 9.8 MB 85.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (3.7.4.3)\nRequirement already satisfied: numpy>=1.15.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (1.20.1)\nRequirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (2.11.3)\nCollecting thinc<8.1.0,>=8.0.2\n  Downloading thinc-8.0.2-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n\u001b[K     |████████████████████████████████| 1.1 MB 89.2 MB/s eta 0:00:01\n\u001b[?25hCollecting tqdm<5.0.0,>=4.38.0\n  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n\u001b[K     |████████████████████████████████| 74 kB 4.1 MB/s  eta 0:00:01\n\u001b[?25hCollecting srsly<3.0.0,>=2.4.0\n  Downloading srsly-2.4.0-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n\u001b[K     |████████████████████████████████| 456 kB 55.9 MB/s eta 0:00:01\n\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n  Downloading cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\nCollecting spacy-legacy<3.1.0,>=3.0.0\n  Downloading spacy_legacy-3.0.1-py2.py3-none-any.whl (7.0 kB)\nRequirement already satisfied: importlib-metadata>=0.20 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy) (3.4.0)\nCollecting typer<0.4.0,>=0.3.0\n  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\nCollecting preshed<3.1.0,>=3.0.2\n  Downloading preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\n\u001b[K     |████████████████████████████████| 126 kB 82.7 MB/s eta 0:00:01\n\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\nCollecting pydantic<1.8.0,>=1.7.1\n  Downloading pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n\u001b[K     |████████████████████████████████| 9.1 MB 55.1 MB/s eta 0:00:01\n\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n  Downloading murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from importlib-metadata>=0.20->spacy) (3.4.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.7)\nCollecting smart-open<4.0.0,>=2.2.0\n  Downloading smart_open-3.0.0.tar.gz (113 kB)\n\u001b[K     |████████████████████████████████| 113 kB 84.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\nRequirement already satisfied: click<7.2.0,>=7.1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\nRequirement already satisfied: MarkupSafe>=0.23 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jinja2->spacy) (1.1.1)\nBuilding wheels for collected packages: smart-open\n  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=27666cdd9a9ee086c08ee215a44605fc02226cf1306208f7a5081f8f7c16b9ed\n  Stored in directory: /home/jovyan/.cache/pip/wheels/83/a6/12/bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\nSuccessfully built smart-open\nInstalling collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, tqdm, thinc, spacy-legacy, pathy, spacy\nSuccessfully installed blis-0.7.4 catalogue-2.0.1 cymem-2.0.5 murmurhash-1.0.5 pathy-0.4.0 preshed-3.0.5 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.2 tqdm-4.59.0 typer-0.3.2 wasabi-0.8.2\n","output_type":"stream"}]},{"cell_type":"code","source":"#import spacy and english resources\nimport spacy\nspacy.cli.download(\"en_core_web_sm\")# dal prompt: python -m spacy download en_core_web_sm\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"corpus = df['reviewText'].tolist()\ntext = corpus[1]\ndoc = nlp(text)","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#POS - Part of Speech\n#DEP - Dependency tree\nfor token in doc:\n    print(token.text, token.pos_, token.dep_)","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"This DET det\ncase NOUN nsubj\nprotects VERB ROOT\nthe DET det\nphone NOUN dobj\nfrom ADP prep\ndamage NOUN pobj\n. PUNCT punct\n","output_type":"stream"}]},{"cell_type":"code","source":"for token in doc:\n    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n            token.shape_, token.is_alpha, token.is_stop)","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"This this DET DT det Xxxx True True\ncase case NOUN NN nsubj xxxx True False\nprotects protect VERB VBZ ROOT xxxx True False\nthe the DET DT det xxx True True\nphone phone NOUN NN dobj xxxx True False\nfrom from ADP IN prep xxxx True True\ndamage damage NOUN NN pobj xxxx True False\n. . PUNCT . punct . False False\n","output_type":"stream"}]},{"cell_type":"code","source":"from spacy import displacy\ndisplacy.render(doc, style=\"dep\")\n# sentence_spans = list(doc.sents)\n# displacy.render(sentence_spans, style=\"dep\")","metadata":{"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"14558b904f04464b9b1545b4ff014a3e-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">case</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">protects</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">phone</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">from</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">damage.</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-14558b904f04464b9b1545b4ff014a3e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-14558b904f04464b9b1545b4ff014a3e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-14558b904f04464b9b1545b4ff014a3e-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-14558b904f04464b9b1545b4ff014a3e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-14558b904f04464b9b1545b4ff014a3e-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-14558b904f04464b9b1545b4ff014a3e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-14558b904f04464b9b1545b4ff014a3e-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-14558b904f04464b9b1545b4ff014a3e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-14558b904f04464b9b1545b4ff014a3e-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-14558b904f04464b9b1545b4ff014a3e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-14558b904f04464b9b1545b4ff014a3e-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-14558b904f04464b9b1545b4ff014a3e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n</g>\n</svg></span>"},"metadata":{}}]},{"cell_type":"code","source":"subject = []\nadjectives = []\nfor token in doc:\n    if token.dep_ == 'nsubj':\n        subject.append(token)\n    if token.pos_ == 'ADJ':\n        adjectives.append(token)\nprint(subject, adjectives)     # non ci sono aggettivi nella frase, solo un soggetto","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[case] []\n","output_type":"stream"}]},{"cell_type":"code","source":"import spacy\nfrom spacy.symbols import nsubj, VERB\n\n# Finding a verb with a subject from below — good\nverbs = []\nfor token in doc:\n    if token.dep == nsubj and token.head.pos == VERB:\n        verbs.append([token.head, token])\nprint(verbs)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[[protects, case]]\n","output_type":"stream"}]},{"cell_type":"code","source":"senteces = corpus[1:6]\nsubject = []\nadjectives = []\nfor sent in senteces:\n    doc = nlp(sent)\n    for token in doc:\n        if token.dep_ == 'nsubj':\n            subject.append(token)\n        if token.pos_ == 'ADJ':\n            adjectives.append(token)\nprint(subject,adjectives)      \n# se prendiamo tante righe in corpus ci dà errore: dobbiamo eliminare le righe vuote prima di farlo partire","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[case, this, case, I, it] [Nice, favorite, Decent, cute, only, hard]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}