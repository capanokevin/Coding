{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data and check for na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Probably my favorite cover! Super sassy and ve...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>This case protects the phone from damage.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>this was another of my favorite ones, thanks f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Decent case but not a lot of protection.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>it is so easy to put on your phone and it prot...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>Much better quality than I expected for the pr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This is one of the best screen protectors I ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This kit included a microfiber cloth and soft ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This was the easiest screen protector to put o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                                         reviewText  overall\n",
       "0      B007D6J64K  Probably my favorite cover! Super sassy and ve...        5\n",
       "1      B007D6J64K          This case protects the phone from damage.        5\n",
       "2      B007D6J64K                                               Nice        4\n",
       "3      B007D6J64K  this was another of my favorite ones, thanks f...        5\n",
       "4      B007D6J64K           Decent case but not a lot of protection.        5\n",
       "...           ...                                                ...      ...\n",
       "29995  B0096QI0QK  it is so easy to put on your phone and it prot...        5\n",
       "29996  B0096QI0QK  Much better quality than I expected for the pr...        5\n",
       "29997  B0096QI0QK  This is one of the best screen protectors I ha...        4\n",
       "29998  B0096QI0QK  This kit included a microfiber cloth and soft ...        5\n",
       "29999  B0096QI0QK  This was the easiest screen protector to put o...        5\n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/amazon_cellphones_multiclass.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin           0\n",
       "reviewText    12\n",
       "overall        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    17695\n",
       "4     5366\n",
       "3     3144\n",
       "1     2121\n",
       "2     1674\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.overall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create binary target varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>bin_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Probably my favorite cover! Super sassy and ve...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>This case protects the phone from damage.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Nice</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>this was another of my favorite ones, thanks f...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Decent case but not a lot of protection.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>it is so easy to put on your phone and it prot...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>Much better quality than I expected for the pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This is one of the best screen protectors I ha...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This kit included a microfiber cloth and soft ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This was the easiest screen protector to put o...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                                         reviewText  overall  \\\n",
       "0      B007D6J64K  Probably my favorite cover! Super sassy and ve...        5   \n",
       "1      B007D6J64K          This case protects the phone from damage.        5   \n",
       "2      B007D6J64K                                               Nice        4   \n",
       "3      B007D6J64K  this was another of my favorite ones, thanks f...        5   \n",
       "4      B007D6J64K           Decent case but not a lot of protection.        5   \n",
       "...           ...                                                ...      ...   \n",
       "29995  B0096QI0QK  it is so easy to put on your phone and it prot...        5   \n",
       "29996  B0096QI0QK  Much better quality than I expected for the pr...        5   \n",
       "29997  B0096QI0QK  This is one of the best screen protectors I ha...        4   \n",
       "29998  B0096QI0QK  This kit included a microfiber cloth and soft ...        5   \n",
       "29999  B0096QI0QK  This was the easiest screen protector to put o...        5   \n",
       "\n",
       "       bin_y  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "29995      1  \n",
       "29996      1  \n",
       "29997      1  \n",
       "29998      1  \n",
       "29999      1  \n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary(row):\n",
    "    if row['overall'] > 3:\n",
    "        val = 1\n",
    "    elif row['overall'] < 3:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n",
    "\n",
    "df['bin_y'] = df.apply(binary, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove NaN and split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This case is so cute the only problem I had with it due to the texture of the case it was hard to get in and out of my pockets'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_na = df[~(df['reviewText'].isna()) & ~(df['bin_y']==-1)]\n",
    "text_0 = df_not_na['reviewText']\n",
    "y = df_not_na['bin_y'].tolist()\n",
    "text_0[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lowercase, remove punctuation, tokenize, lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'case', 'is', 'so', 'cute', 'the', 'only', 'problem', 'i', 'had', 'with', 'it', 'due', 'to', 'the', 'texture', 'of', 'the', 'case', 'it', 'wa', 'hard', 'to', 'get', 'in', 'and', 'out', 'of', 'my', 'pocket']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "text = text_0.str.lower().str.replace('[^\\w\\s]',' ')\n",
    "text = text.str.split()\n",
    "# text = text.apply(lambda x: [lemmatizer.lemmatize(word) for sentence in x for word in sentence])\n",
    "text = text.apply(lambda x: [lemmatizer.lemmatize(sent) for sent in x])\n",
    "print(text[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK stopwords can be found at [this link](https://gist.github.com/sebleier/554280), downloaded, custiomized and imported as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'case', 'is', 'so', 'cute', 'the', 'only', 'problem', 'i', 'had', 'with', 'it', 'due', 'to', 'the', 'texture', 'of', 'the', 'case', 'it', 'wa', 'hard_to_get', 'in', 'and', 'out', 'of', 'my', 'pocket']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['good', 'many', 'love', 'excellent', 'would'])\n",
    "\n",
    "bigram = Phrases(text, min_count=5, threshold=1, common_terms=stop)\n",
    "print(bigram[text[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold parameter:\n",
    "<img src='img/phrases_threshold.PNG' width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'case', 'is', 'so', 'cute', 'the', 'only', 'problem', 'i', 'had', 'with', 'it', 'due', 'to', 'the', 'texture', 'of', 'the', 'case', 'it', 'wa', 'hard_to_get', 'in', 'and', 'out', 'of', 'my', 'pocket']\n"
     ]
    }
   ],
   "source": [
    "bigrams = [bigram[item] for item in text]\n",
    "ngrams = [bigram[item] for item in bigrams]\n",
    "print(ngrams[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['probably', 'my', 'favorite', 'cover', 'super', 'sassy', 'and', 'very', 'protective', 'i', 'am', 'very', 'abusive', 'of', 'my', 'phone', 'and', 'this', 'case', 'held_up_very_well', 'after', 'a', 'year', 'the', 'color', 'started', 'to', 'wear', 'a', 'bit', 'but', 'it', 'continued', 'to', 'protect_my_phone', 'very', 'well', 'i', 'would', 'buy', 'it', 'again']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'probably favorite cover super sassy protective abusive phone case held_up_very_well year color started wear bit continued protect_my_phone well buy'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['good', 'bad', 'dont', 'many', 'love', 'excellent', 'would', 'perfect', 'even', 'great'])\n",
    "print(ngrams[0])\n",
    "train_sentences = []\n",
    "for row in ngrams:\n",
    "    train_sentences.append(' '.join([item for item in row if item not in stop]))\n",
    "# train_sentences = [' '.join(item) for item in ngrams]\n",
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-727f19d5c524>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not_na['reviewText'] = train_sentences\n"
     ]
    }
   ],
   "source": [
    "df_not_na['reviewText'] = train_sentences\n",
    "df_not_na.to_csv('data/amazon_cellphones_binary.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words:\n",
    "<img src='img/bow.PNG' width='600'>\n",
    "\n",
    "Term frequency - inverse document frequency:\n",
    "<img src='img/tfidf.jpeg' width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably favorite cover super sassy protective abusive phone case held_up_very_well year color started wear bit continued protect_my_phone well buy\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=1000)\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "print(train_sentences[0])\n",
    "X = vectorizer.fit_transform(train_sentences)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "X = X.toarray()\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzo/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "3it [00:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  [86.43039591315454, 86.74968071519795, 86.79546543190165]\n",
      "recall:  [0.8726345236136251, 0.8758882829284416, 0.8769256253105847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=False, random_state=1)\n",
    "model = tree.DecisionTreeClassifier(max_leaf_nodes=10, max_depth=5)\n",
    "# model = LogisticRegression(class_weight=None)\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "cvscores = []\n",
    "cvrecall = []\n",
    "\n",
    "for train, validation in tqdm(kfold.split(x_train, y_train)):\n",
    "    model.fit(x_train[train],y_train[train])\n",
    "    predicted = model.predict(x_train[validation])\n",
    "    scores = accuracy_score(predicted, y_train[validation])\n",
    "    recall = recall_score(predicted, y_train[validation])\n",
    "    cvrecall.append(recall)\n",
    "    cvscores.append(scores * 100)\n",
    "\n",
    "print(\"accuracy: \",cvscores)\n",
    "print(\"recall: \",cvrecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.13      0.22      1138\n",
      "           1       0.87      0.99      0.93      6916\n",
      "\n",
      "    accuracy                           0.87      8054\n",
      "   macro avg       0.75      0.56      0.57      8054\n",
      "weighted avg       0.84      0.87      0.83      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validated grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/lorenzo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.13 s, sys: 471 ms, total: 4.6 s\n",
      "Wall time: 41.4 s\n",
      "Best: 0.833146 using {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.785882 (0.016621) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.818670 (0.006715) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.791339 (0.015944) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.814290 (0.009004) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.795607 (0.008950) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.821525 (0.006836) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.804787 (0.005259) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.829279 (0.006568) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.809547 (0.007438) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.831245 (0.002615) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.808148 (0.000335) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.827585 (0.003748) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.786316 (0.007128) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.817829 (0.002409) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.794670 (0.011004) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.820345 (0.005182) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.792685 (0.004021) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.822800 (0.008161) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.806689 (0.001461) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.832270 (0.004458) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.813133 (0.005167) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.833146 (0.002983) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.813564 (0.005838) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.831428 (0.008429) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "#cross_validated_grid_search for Random Forest\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "param_grid = {'n_estimators': [10, 100],\n",
    "               'criterion': ['gini', 'entropy'],\n",
    "               'max_depth': [5, 10],\n",
    "               'min_samples_split': [2, 10, 20]}\n",
    "\n",
    "#cross_validated_grid_search for SVC\n",
    "# model = svm.SVC()\n",
    "# param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv=3, verbose=2, n_jobs=-1, scoring='f1_weighted')\n",
    "# Fit the random search model\n",
    "%time grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "#print grid search results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.53      0.45      1138\n",
      "           1       0.92      0.86      0.89      6916\n",
      "\n",
      "    accuracy                           0.82      8054\n",
      "   macro avg       0.65      0.70      0.67      8054\n",
      "weighted avg       0.84      0.82      0.83      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "predicted = best_model.predict(x_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = best_model.estimators_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(estimator,\n",
    "                proportion=True,\n",
    "                out_file=\"tree.dot\",\n",
    "                feature_names=feature_names,\n",
    "                class_names=['negative', 'positive'],\n",
    "                filled=True,\n",
    "                rounded=True,\n",
    "                max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: dot\r\n"
     ]
    }
   ],
   "source": [
    "!dot -Tpng tree.dot -o tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng tree.dot -o tree.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
